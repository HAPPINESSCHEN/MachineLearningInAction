{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.决策树\n",
    "## 3.1.原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树是一种监督式分类方法。\n",
    "\n",
    "在一个类型和特征值已知的结构化数据集上，根据数据类型的概率，建立一个树形结构，用于数据分类。\n",
    "\n",
    "训练一个决策树，需要在每次划分时，以最大信息增益的特征进行划分。\n",
    "\n",
    "使用一个决策树预测，需要从树的根节点，一步步进行判断，最后在叶节点得到预测的分类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.2.信息增益的计算\n",
    "### 3.2.1.建立结构化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSet = [['sunny', 'high', 'false', 'hot', 'yes'],\n",
    "          ['sunny', 'high', 'false', 'hot', 'yes'],\n",
    "          ['overcast', 'high', 'false', 'mild', 'yes'],\n",
    "          ['overcast', 'normal', 'false', 'mild', 'yes'],\n",
    "          ['overcast', 'normal', 'false', 'mild', 'yes'],\n",
    "          ['overcast', 'normal', 'false', 'mild', 'yes'],\n",
    "          ['rainy', 'normal', 'true', 'cool', 'yes'],\n",
    "          ['rainy', 'normal', 'true', 'cool', 'yes'],\n",
    "          ['rainy', 'normal', 'true', 'cool', 'yes'],\n",
    "          ['sunny', 'high', 'false', 'hot', 'no'],\n",
    "          ['sunny', 'high', 'false', 'hot', 'no'],\n",
    "          ['sunny', 'high', 'true', 'mild', 'no'],\n",
    "          ['rainy', 'high', 'true', 'mild', 'no'],\n",
    "          ['rainy', 'normal', 'true', 'cool', 'no']]\n",
    "features = ['outlook', 'humidity', 'windy', 'temperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2.计算信息增益的函数\n",
    "信息量为概率的负对数，概率越小，信息量越大\n",
    "$$l(x_{i})=-log_{2}p(x_{i})$$\n",
    "香农熵为信息量的期望，统计平均\n",
    "$$H=E[l(x_{i})]=-\\sum_{i=1}^{n}p(x_{i})\\cdot log_{2}p(x_{i})$$\n",
    "信息增益为划分前的信息熵减去划分后的各个子类信息熵之和\n",
    "$$G=H_{orig}-\\sum_{i=1}^{K}H_{divd_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    计算香农熵\n",
    "    参数：\n",
    "        dataSet -- 数据集，包含不同类型\n",
    "    输出：\n",
    "        shannonEnt -- 香农熵\n",
    "    \"\"\"\n",
    "    #求数据集大小\n",
    "    numEntries = len(dataSet)\n",
    "    #新建一个用于统计各个类型数目的字典\n",
    "    labelCounts = {}\n",
    "    #遍历数据集中的每个数据\n",
    "    for featVec in dataSet:\n",
    "        #类型为数据中的最后一项\n",
    "        currentLabel = featVec[-1]\n",
    "        #如果之前没有记录该类型\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            #添加新的一项记录\n",
    "            labelCounts[currentLabel] = 0\n",
    "        #计数\n",
    "        labelCounts[currentLabel] += 1\n",
    "    #初始化香农熵\n",
    "    shannonEnt = 0.0\n",
    "    #遍历所有类型\n",
    "    for key in labelCounts:\n",
    "        #计算概率，古典概型\n",
    "        prob = np.float(labelCounts[key])/numEntries\n",
    "        #根据公式计算香农熵\n",
    "        shannonEnt -= prob * log(prob, 2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet, features):\n",
    "    \"\"\"\n",
    "    选择最好的划分参照特征，也就是使得信息增益最大的划分方式\n",
    "    参数：\n",
    "        dataSet -- 数据集\n",
    "        features -- 特征名\n",
    "    返回：\n",
    "        bestFeature -- 最好的参照类\n",
    "        infoGains -- 信息增益，字典\n",
    "    \"\"\"\n",
    "    #建立一个字典，存储信息增益\n",
    "    infoGains = {}\n",
    "    #求特征数，-1是去掉标签\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    #求数据集的香农熵\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    #初始化最佳信息增益，和最好的参照特征\n",
    "    bestInfoGain = 0.0\n",
    "    bestFeature = -1\n",
    "    #遍历每个特征\n",
    "    for i in range(numFeatures):\n",
    "        #取每个数据的第i个特征值\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        #把这些特征值作为一个集合\n",
    "        uniqueVals = set(featList)\n",
    "        #初始化划分后的熵\n",
    "        newEntropy = 0.0\n",
    "        #遍历集合中的特征值\n",
    "        for value in uniqueVals:\n",
    "            #取第i个特征值为value子集\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            #计算概率\n",
    "            prob = len(subDataSet) / np.float(len(dataSet))\n",
    "            #计算划分后的熵，为各个子集熵的期望\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        #计算信息增益\n",
    "        infoGain = baseEntropy - newEntropy\n",
    "        #加入列表\n",
    "        infoGains[features[i]] = infoGain\n",
    "        #如果当前以i特征划分得到的信息增益大于之前的最大值\n",
    "        if (infoGain > bestInfoGain):\n",
    "            #加冕为王\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature, infoGains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有特征的信息增益是：\n",
      "{'outlook': 0.2467498197744391, 'humidity': 0.15183550136234136, 'windy': 0.04812703040826927, 'temperature': 0.029222565658954647}\n",
      "\n",
      "最好的分类特征是——outlook\n"
     ]
    }
   ],
   "source": [
    "bestFeature, infoGains = chooseBestFeatureToSplit(dataSet, features)\n",
    "print(\"所有特征的信息增益是：\\n{}\\n\".format(infoGains))\n",
    "print(\"最好的分类特征是——{}\".format(features[bestFeature]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
